{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "# This is empirically verified, DO NOT MODIFY\n",
    "PEAK_REL_AMP = 0.563\n",
    "PEAK_REL_AMP_DB = 20. * np.log10(PEAK_REL_AMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify WAV stimuli for MEG experiment\n",
    "\n",
    "WAV-files used in the MEG should\n",
    "\n",
    "* be sampled at 44.1 kHz\n",
    "* be saved as 16-bit integer precision\n",
    "\n",
    "If this notebook runs without error, that is the case. In addition, the final plot can be inspected to see the largest absolute amplitude of the stimulus set used. Due to mismatches between the input- and output-levels of the various components in the audio-stream:\n",
    "\n",
    " > __the peak amplitude should never exceed 0.563 (-4.99 dB), _i.e._, 56.3% of maximum volume output__\n",
    " \n",
    " ## File layout\n",
    " \n",
    "Place all the files in a single folder, and set the variable `wavdir` (below) to point to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proj_name = 'MEG_EEG-Training'\n",
    "wavdir = os.path.join('/aux', proj_name, 'wav_stimuli')\n",
    "wavdir = '/Users/cjb/tmp/rasha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.expanduser(wavdir)):\n",
    "    raise IOError('Invalid wav-directory: {:s}'.format(wavdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/cjb/src/git/meeg-cfin/stimulation/utilities')\n",
    "from wavhelpers import (list_wavs_in_dir, get_wav, wavlist_to_wavarr)\n",
    "Fs = 44100.  # get_wav hard-coded to raise error if not 44.1 kHz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of pathnames to the WAV-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wavnames = list_wavs_in_dir(wavdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read each WAV into memory\n",
    "\n",
    "Each file is read into a list of 2D-arrays, after which we know the duration of the longest stimulus. The function `wavlist_to_wavarr` then zero-pads each array to have equal duration, and returns a 3D array with dimensions `n_files x n_channels x n_timepoints`, where `n_channels` is either 1 (mono) or 2 (stereo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wavlist = []\n",
    "for fname in wavnames:\n",
    "    wavlist += [get_wav(fname)]\n",
    "wavarr = wavlist_to_wavarr(wavlist)\n",
    "del wavlist\n",
    "\n",
    "# now data is guaranteed to be 16 bit short\n",
    "maxVal = 2**15 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot every N:th WAV-file\n",
    "\n",
    "Currently plots only left channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_every_nth = 2\n",
    "timepoints = np.arange(0, wavarr.shape[2]/Fs, 1./Fs)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "for nwav in range(0, wavarr.shape[0], plot_every_nth):\n",
    "    ax.plot(timepoints, wavarr[nwav,0,:].astype(float) / np.float(maxVal),\n",
    "            label=os.path.basename(wavnames[nwav]))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The stimulus envelope (peak value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# max_env = np.abs(wavarr).max(axis=0).astype(float) / np.float(maxVal)\n",
    "max_env = 20. * np.log10(np.abs(wavarr).max(axis=0).astype(float) /\n",
    "                         np.float(maxVal))\n",
    "max_stim_env = max_env.max()\n",
    "print('The maximum stimulus envelope is {:.3f} '\n",
    "      '({:.3f} dB)'.format(10**(max_stim_env / 20.), max_stim_env))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A plot of the peak range for all stimuli\n",
    "\n",
    "This plots the peak absolute values of the stimuli, in dB relative to the maximum possible in the 16-bit wav file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "for ww in range(wavarr.shape[0]):\n",
    "    ax.plot(timepoints, \n",
    "            20. * np.log10(np.abs(wavarr[ww, 0, :]).astype(float) /\n",
    "                           np.float(maxVal)),\n",
    "            label=os.path.basename(wavnames[ww]))\n",
    "ax.set_ylim(-9., 0.)\n",
    "ax.legend()\n",
    "_ = ax.set_yticks([0., max_stim_env, -3., -6., -9.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What should I do with my stimuli?\n",
    "\n",
    "Now that you know the peak envelope of your stimulus set, we can calculate whether and how much additional dampening of the stimuli is required for no clipping to occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "att_factor = PEAK_REL_AMP / 10**(max_stim_env / 20.)\n",
    "if max_stim_env > PEAK_REL_AMP_DB:\n",
    "    print('You should attenuate your stimuli by '\n",
    "          'a factor of {:.3f} ({:.3f} dB)'.format(att_factor,\n",
    "                                                  20 * np.log10(att_factor)))\n",
    "else:\n",
    "    print('Your stimuli are sufficiently damped, '\n",
    "          'you are using {:.1f}% of the range.'.format(100./att_factor))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
